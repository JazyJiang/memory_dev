# T5 seq2seq + PKM(hashing memory) hyperparameter sweep candidates
# Note: T5-small hidden_dim(d_model)=512 is fixed unless you change base_model.

strategy: t5_seq2seq  # fixed: only sweep t5_seq2seq (exclude decoder-only)

# ----- Training (global) -----
train.learning_rate: [3.0e-4]
train.batch_size: [256]

# ----- PKM enable + placement -----
pkm.t5_seq2seq.pk_is_enabled: [true]

# placement：仅 sweep decoder 侧（encoder 侧固定不放 memory layer）
placement_pairs:
  - {enc: "", dec: "3"}

# ----- PKM capacity / retrieval -----
# 用 capacity_pairs 做“成对扫描”，避免 pk_mem_n_keys × pk_topk 的笛卡尔积
capacity_pairs:
  - {n_keys: 1024, topk: 1024}
  - {n_keys: 1024, topk: 512}
  - {n_keys: 512, topk: 256}
  - {n_keys: 512, topk: 512}
  - {n_keys: 1024, topk: 256}

# ----- PKM internal dims -----
pkm.t5_seq2seq.pk_mem_k_dim: [512]
pkm.t5_seq2seq.pk_mem_v_dim: [-1]

# ----- PKM optimizer knobs -----
pkm.t5_seq2seq.pk_value_fixed_lr: ["tied"]
pkm.t5_seq2seq.pk_value_weight_decay: [0.0]

# ----- PKM switches -----
pkm.t5_seq2seq.pk_mem_gated: [false]
pkm.t5_seq2seq.pk_mem_share_values: [false]

# ----- Usually keep fixed (reduce interactions) -----
pkm.t5_seq2seq.pk_swilu_projection: [true]  # keep consistent with current default usage
pkm.t5_seq2seq.pk_peer_variant: [false]  # keep off unless you explicitly want PEER